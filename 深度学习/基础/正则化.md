<center><b>深度学习中的正则化</b></center>

机器学习中的一个核心问题是设计不仅在训练数据上表现好，并且能在新数据上泛化好的算法。在机器学习中，许多策略显式地被设计为减少测试误差（可能会以增大训练误差为代价）。这些策略统称为正则化。

* [BatchNormalization](BatchNormalization.md)  
* [L1、L2正则化](L1,L2正则化.md)  
* 数据增强  
* Early Stopping  
* 多任务学习  
* [Bagging](https://github.com/imhuay/Algorithm_Interview_Notes-Chinese/blob/master/A-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/A-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md#bagging-%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95)  
* [Dropout](https://github.com/imhuay/Algorithm_Interview_Notes-Chinese/blob/master/A-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/A-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md#dropout-%E7%AD%96%E7%95%A5)  

* 对抗训练  









**参考**
[1] [深度学习](resource/正则化/dlbook_cn_public.pdf)

